{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAT-UCCA.ipynb",
      "provenance": [],
      "mount_file_id": "1LyZDboJeaTXymUES8N5RT3r6GHGIgr_d",
      "authorship_tag": "ABX9TyMr/YzpVTZbzz9JAfEvDnsL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasivan/GAT-UCCA/blob/main/GAT_UCCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onbdS-alSDnR"
      },
      "source": [
        "# Parameters to define"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc8O5i4vLaAS"
      },
      "source": [
        "pos_dim = 20 #position concatenation dimension, set to 0 to disable the feature, must be even\n",
        "edge_dim = 12 #edge label concatenation dimension, set to 0 to disable the feature\n",
        "Train_trial = 20 # Number of set of 5 the model is trained for"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03ViXP3fz4uk"
      },
      "source": [
        "##Python modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwVgKXh-zAWu"
      },
      "source": [
        "'''Download functions'''\n",
        "!pip install transformers\n",
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install -q torch-geometric\n",
        "\n",
        "'''IMPORT'''\n",
        "import xml.etree.ElementTree as ET # extract tree labels\n",
        "\n",
        "import torch # for neural network\n",
        "import torch.nn as nn # for neural network functions like dropout\n",
        "from transformers import BertTokenizer, BertModel # for BERT embeddings\n",
        "\n",
        "from torch_geometric.data import Data # for GAT\n",
        "from torch_geometric.nn import GATv2Conv # for GAT\n",
        "from math import sin, cos, ceil # for position embedding and batching\n",
        "\n",
        "from sklearn.model_selection import train_test_split # for splitting data\n",
        "import random # for shuffling\n",
        "import time # for time stamp\n",
        "\n",
        "'''Run functions once'''\n",
        "# Obtain pre-trained BERT word embeddings\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "# Load pre-trained model (weights)\n",
        "Bnet = BertModel.from_pretrained('textattack/bert-base-uncased-snli',\n",
        "                                  output_hidden_states = True) # Whether the model returns all hidden-states.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_-TUF8RvgUT"
      },
      "source": [
        "##Pre-processing functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzGOg3KAtrLV"
      },
      "source": [
        "# Processing XML file\n",
        "def XML_processing(file):\n",
        "  node2tag = {} # dict[node] = 'word/tag'\n",
        "  parent2children = {} # dict[parent] = [children]\n",
        "  sent = '' # sentence in a string\n",
        "  tree = ET.parse(file)\n",
        "  root = tree.getroot()\n",
        "  for layer in root.iter('layer'): #Iterated through layers of trees, layer 0 => words layer 1 => nodes\n",
        "    if layer.attrib['layerID'] == '0':\n",
        "      for node in layer.iter('node'):\n",
        "        for attribute in node.iter('attributes'):\n",
        "          node2tag[node.attrib['ID']] = attribute.attrib['text'] # leaf nodes are matched to words\n",
        "          sent += attribute.attrib['text'] + ' '\n",
        "    else:\n",
        "      node2tag['1.1'] = 'X' # Add root Node labelled X\n",
        "      for node in layer.iter('node'):\n",
        "        e = []\n",
        "        for edge in node.iter('edge'):\n",
        "          e.append(edge.attrib['toID'])\n",
        "          parent2children[node.attrib['ID']] = e\n",
        "          if edge.attrib['type'] != 'Terminal':\n",
        "            node2tag[edge.attrib['toID']] = edge.attrib['type'] # non-leaf nodes are matched to edge label\n",
        "  return node2tag, parent2children, sent[0:-1]\n",
        "\n",
        "# Enumerating all nodes in topological order, leaves to root\n",
        "def enum_node(parent2children, node2tag):\n",
        "    L0 = {}\n",
        "    L1 = {}\n",
        "    for i, key in enumerate(node2tag.keys()):\n",
        "      if '0.' in key:\n",
        "        L0[key]=i\n",
        "    for i, key in enumerate(parent2children.keys()):\n",
        "      L1[key] = i+len(L0)\n",
        "    return L0, L1, {**L0, **L1}\n",
        "\n",
        "# Edge_index: list of source nodes and target nodes as two lists in a tensor\n",
        "def edge_index(parent2children, L):\n",
        "    s = []\n",
        "    t = []\n",
        "    for key in parent2children.keys():\n",
        "      for val in parent2children[key]:\n",
        "        s.append(key) # edge source\n",
        "        t.append(val) # edge target\n",
        "    edge_index = [[L[s[i]] for i in reversed(range(len(s)))], [L[t[i]] for i in reversed(range(len(t)))]]\n",
        "\n",
        "    return torch.tensor(edge_index, dtype=torch.long)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QRuANo6Hl6Z"
      },
      "source": [
        "def get_BERT_emb(sent, node2tag):\n",
        "    marked_text = \"[CLS] \" + sent + \" [SEP]\"\n",
        "    tokenized_text = tokenizer.tokenize(marked_text) # Tokenize our sentence with the BERT tokenizer.\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text) # convert token to index\n",
        "\n",
        "    # Mark each of the tokens from first sentence as belonging to sentence \"1\".\n",
        "    segments_ids = [1] * len(tokenized_text)\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "    segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "    # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "    Bnet.eval() # Call pre-trained BERT model\n",
        "    with torch.no_grad(): # Ensure weights don't update\n",
        "        outputs = Bnet(tokens_tensor, segments_tensors)\n",
        "        hidden_states = outputs[2]\n",
        "    \n",
        "    # Sum last 4 layers to get token embeddings\n",
        "    token_embeddings = torch.squeeze(hidden_states[-1].add(hidden_states[-2].add(hidden_states[-3].add(hidden_states[-4]))))\n",
        "    \n",
        "    # Combines tokens embeddings to get word embeddings e.g. vin ##ken --> vinken\n",
        "    emb, j = [], 0\n",
        "    W = list(node2tag.values())\n",
        "    for i in range(len(tokenized_text)-2): # iterate through BERT token embeddings\n",
        "      if W[j].lower().startswith(tokenized_text[i+1]) == True:\n",
        "        emb.append(token_embeddings[i+1])\n",
        "        j += 1\n",
        "      else:\n",
        "        emb[-1] = emb[-1].add(token_embeddings[i+1])\n",
        "    \n",
        "    return emb # returns list of word embeddings\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeT8jLa15JWs"
      },
      "source": [
        "def preprocessing(file):\n",
        "  node2tag, parent2children, sent = XML_processing(file)\n",
        "  L0, L1, L = enum_node(parent2children, node2tag) #L0 => layer0; L1 => layer1 ; L => all layers\n",
        "\n",
        "  # BERT Embeddings\n",
        "  emb = get_BERT_emb(sent, node2tag) # list of BERT embedding for leaf nodes\n",
        "  BERT_emb_size = emb[0].shape[0] # dimension of BERT embedding (768)\n",
        "\n",
        "  # Append small magnitude random embedding for non-leaf nodes\n",
        "  for i in range(len(parent2children)):\n",
        "    emb.append(torch.mul(torch.rand(BERT_emb_size, dtype=torch.float, requires_grad=True), 0.001))\n",
        "\n",
        "  # Concatenating Position Embeddings (0 vector for non-leaf nodes)\n",
        "  for t in range(len(L)):\n",
        "      if t<len(L0):\n",
        "        pos = []\n",
        "        for k in range(int(pos_dim/2)):\n",
        "            pos.append(sin(t/(10000**(2*k/pos_dim))))\n",
        "            pos.append(cos(t/(10000**(2*k/pos_dim))))\n",
        "        emb[t] = torch.cat((emb[t], torch.Tensor(pos)))\n",
        "      else:\n",
        "        emb[t] = torch.cat((emb[t], torch.zeros(pos_dim)))\n",
        "\n",
        "  # Concatenating Label Embeddings (0 vector for leaf nodes)\n",
        "  for t in range(len(node2tag)):\n",
        "    if t<len(L0):\n",
        "      emb[t] = torch.cat((emb[t], torch.zeros(edge_dim)))\n",
        "    else:\n",
        "      #[0] to get first letter so that C-remote => C\n",
        "      emb[t] = torch.cat((emb[t], edge_emb[list(node2tag.values())[t][0]]))\n",
        "\n",
        "  # Combine embeddings into a tensor\n",
        "  node_emb =  torch.stack(emb, dim=0).to(device)\n",
        "  edge_idx = edge_index(parent2children, L).to(device)\n",
        "\n",
        "  return node_emb, edge_idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p5jNtFxeCsT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07bdf67b-7fdd-47df-a2ec-06254d507067"
      },
      "source": [
        "''' Unzip XML files '''\n",
        "!mkdir sentence-B-full\n",
        "!mkdir sentence-A-full\n",
        "%cd /content\n",
        "!unzip /content/sentence-B-full.zip -d /content/sentence-B-full\n",
        "!unzip /content/sentence-A-full.zip -d /content/sentence-A-full"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘sentence-B-full’: File exists\n",
            "mkdir: cannot create directory ‘sentence-A-full’: File exists\n",
            "/content\n",
            "Archive:  /content/drive/MyDrive/sentence-B-full.zip\n",
            "replace /content/sentence-B-full/190740.xml? [y]es, [n]o, [A]ll, [N]one, [r]ename: Archive:  /content/drive/MyDrive/sentence-A-full.zip\n",
            "replace /content/sentence-A-full/190740.xml? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZhxXOEMSDnR"
      },
      "source": [
        "# Preprocessing parameters\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialising random embedding for the edge labels\n",
        "edge_label = ['P', 'S', 'A', 'D', 'C', 'E', 'N', 'R', 'H', 'L', 'G', 'F', 'X', 'Q', 'U', 'T']\n",
        "edge_emb = {}\n",
        "for label in edge_label:\n",
        "    edge_emb[label] = torch.rand(edge_dim, dtype = torch.float, requires_grad=True)\n",
        "\n",
        "# Preprocessing sentences\n",
        "%cd /content/sentence-B-full\n",
        "preprocessB = []\n",
        "for i in range(4906,9840): # total = 9840\n",
        "  file1 = '1' + \"%04d\" % (i+1) + '0.xml'\n",
        "  node_emb1, edge_idx1 = preprocessing(file1)\n",
        "  preprocessB.append((node_emb1, edge_idx1))\n",
        "\n",
        "%cd /content/sentence-A-full\n",
        "preprocessA = []\n",
        "for i in range(4906,9840):\n",
        "  file1 = '1' + \"%04d\" % (i+1) + '0.xml'\n",
        "  node_emb1, edge_idx1 = preprocessing(file1)\n",
        "  preprocessA.append((node_emb1, edge_idx1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbtEgvZ_SDnR"
      },
      "source": [
        "# Store relatedness score to sentence pairs\n",
        "%cd /content\n",
        "with open('/content/relatedness-score-full.txt', 'r') as f:\n",
        "    full_target = [torch.FloatTensor([float(line)]).to(device) for line in f.readlines()]\n",
        "\n",
        "# Group sentence A, sentence B and relatedness score\n",
        "preprocess = list(zip(preprocessA, preprocessB, full_target[4906:9840]))\n",
        "\n",
        "# Split data into train and test set\n",
        "preprocess_train = list(zip(preprocessA[:4439], preprocessB[:4439], full_target[4906:9345]))\n",
        "preprocess_test = list(zip(preprocessA[4439:], preprocessB[4439:], full_target[9345:]))\n",
        "print(len(preprocess_train), len(preprocess_test))\n",
        "del preprocessA\n",
        "del preprocessB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MuoE1qESDnR"
      },
      "source": [
        "##Graph Attention Network model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkWP4y3WSDnR"
      },
      "source": [
        "# Graph Attention Network\n",
        "class GAT(torch.nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super(GAT, self).__init__()\n",
        "    self.conv1 = GATv2Conv(in_channels, hidden, heads= heads, concat=False, add_self_loops= True)\n",
        "    self.conv2 = GATv2Conv(hidden, out_channels, heads= heads, concat=False, add_self_loops= True)\n",
        "    self.dropout1 = nn.Dropout2d(0.1)\n",
        "    self.linear = nn.Linear(out_channels, linear_hidden)\n",
        "\n",
        "  def forward(self, preprocessing):\n",
        "    output = self.dropout1(self.conv1(preprocessing[0], preprocessing[1]))\n",
        "    output = self.dropout1(self.conv2(output, preprocessing[1]))\n",
        "    output = self.linear(output)\n",
        "    output = torch.mean(output, dim=0)\n",
        "    output = torch.unsqueeze(output, 0)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9b2_UXLSDnR"
      },
      "source": [
        "## Test/Val"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_4qRvufSDnR"
      },
      "source": [
        "def train(model, data, data_size):\n",
        "\n",
        "    print('----------TRAINING----------')\n",
        "    optimiser = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
        "    for epoch in range(epochs):\n",
        "        model.train().to(device)\n",
        "        optimiser.zero_grad()\n",
        "\n",
        "        preprocess_rand = list(random.sample(data, data_size))\n",
        "        batch_loss = 0\n",
        "\n",
        "        for i in range(ceil(data_size/batch_size)):\n",
        "            sim, target = [], []\n",
        "            if i+1 < ceil(data_size/batch_size) or data_size % batch_size == 0:\n",
        "                batch = batch_size\n",
        "            else:\n",
        "                batch = data_size % batch_size\n",
        "            for j in range(batch):\n",
        "                out1r = model(preprocess_rand[j + i*batch_size][0]).to(device)\n",
        "                out2r = model(preprocess_rand[j + i*batch_size][1]).to(device)\n",
        "                target.append(preprocess_rand[j + i*batch_size][2])\n",
        "                sim.append((abs(cosine(out1r, out2r))*4)+1) # rescale to range 1 to 5\n",
        "\n",
        "            Csim = torch.cat(tuple(sim), 0).to(device)\n",
        "            targets = torch.cat(tuple(target), 0).to(device)\n",
        "\n",
        "            loss = criterion(Csim, targets)\n",
        "            loss.backward(retain_graph=True)\n",
        "            optimiser.step()\n",
        "            nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)\n",
        "            \n",
        "            batch_loss += loss*batch\n",
        "\n",
        "    print('Epoch:', epoch, 'loss:', '%.3f' % (batch_loss.item()/data_size))\n",
        "    return batch_loss.item()/data_size\n",
        "\n",
        "def eval(model, data, data_size):\n",
        "    start = time.process_time()\n",
        "    print('----------VALIDATION----------')\n",
        "    model.eval().to(device)\n",
        "    sim, target = [], []\n",
        "    for j in range(data_size):\n",
        "        out1r = model(data[j][0]).to(device)\n",
        "        out2r = model(data[j][1]).to(device)\n",
        "        target.append(data[j][2])\n",
        "        sim.append((abs(cosine(out1r, out2r))*4)+1)\n",
        "\n",
        "    Csim = torch.cat(tuple(sim), 0).to(device)\n",
        "    Csim = (Csim * 10).round() / 10\n",
        "    targets = torch.cat(tuple(target), 0).to(device)\n",
        "\n",
        "    loss_MSE = criterion(Csim, targets)\n",
        "    vx = Csim - torch.mean(Csim)\n",
        "    vy = targets - torch.mean(targets)\n",
        "    loss_pearson = torch.sum(vx * vy) / (torch.sqrt(torch.sum(vx ** 2)) * torch.sqrt(torch.sum(vy ** 2)))\n",
        "    \n",
        "    from scipy import stats\n",
        "    loss_spearman = stats.spearmanr(Csim.tolist(), targets.tolist())\n",
        "\n",
        "    print('loss_MSE:', '%.3f' % loss_MSE.item())\n",
        "    print('loss_pearson:', '%.3f' % loss_pearson.item())\n",
        "    print('loss_spearman:', '%.3f' % loss_spearman[0])\n",
        "\n",
        "    return loss_MSE.item(), loss_pearson.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "198HmJ-dSDnS"
      },
      "source": [
        "## Run code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F1qrk_3SDnS"
      },
      "source": [
        "# Parameters 'Siamese'\n",
        "heads = 1\n",
        "hidden = 500\n",
        "out_channels = 400\n",
        "linear_hidden = 200\n",
        "epochs = 5\n",
        "batch_size = 15\n",
        "lr = 0.000009\n",
        "\n",
        "# Siamese network (mean of all nodes)\n",
        "model = GAT(preprocess_train[0][0][0].shape[1], out_channels).to(device)\n",
        "cosine = nn.CosineSimilarity(dim=1) # similarity function\n",
        "criterion = torch.nn.MSELoss() # Loss function\n",
        "\n",
        "f = open('epochs_loss.txt', 'w')\n",
        "f.writelines('EPOCHS , LOSS_TRAIN , LOSS_DEV , Pearson')\n",
        "f.close()\n",
        "loss_pearson = 0\n",
        "trial=0\n",
        "while trial < Train_trial :\n",
        "  print('\\nTRIAL:', trial)\n",
        "  loss_train = train(model, preprocess_train, len(preprocess_train))\n",
        "  loss_eval, loss_pearson1 = eval(model, preprocess_test, len(preprocess_test))\n",
        "  trial +=1\n",
        "  f = open('epochs_loss.txt', 'a')\n",
        "  f.writelines(f'\\n {5*trial} , {loss_train:.3f} , {loss_eval:.3f} , {loss_pearson.item():.3f}')\n",
        "  f.close()\n",
        "  if loss_pearson1 > loss_pearson:\n",
        "      loss_pearson = loss_pearson1\n",
        "      torch.save(model.state_dict(), 'model-similarity.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_fTZaGhSDnT"
      },
      "source": [
        "# Preprocessing sentences\n",
        "%cd /content/sentence-B-full\n",
        "preprocessB = []\n",
        "for i in range(4906): # total = 9840\n",
        "  file1 = '1' + \"%04d\" % (i+1) + '0.xml'\n",
        "  node_emb1, edge_idx1 = preprocessing(file1)\n",
        "  preprocessB.append((node_emb1, edge_idx1))\n",
        "\n",
        "%cd /content/sentence-A-full\n",
        "preprocessA = []\n",
        "for i in range(4906):\n",
        "  file1 = '1' + \"%04d\" % (i+1) + '0.xml'\n",
        "  node_emb1, edge_idx1 = preprocessing(file1)\n",
        "  preprocessA.append((node_emb1, edge_idx1))\n",
        "\n",
        "%cd /content\n",
        "\n",
        "\n",
        "#Group sentence A, sentence B and relatedness score\n",
        "preprocess_eval = list(zip(preprocessA, preprocessB, full_target[:4906]))\n",
        "del preprocessA\n",
        "del preprocessB\n",
        "_, _ = eval(model, preprocess_eval, len(preprocess_eval))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvnjAfbFSDnT"
      },
      "source": [
        "model1 = GAT(preprocess_eval[0][0][0].shape[1], out_channels).to(device)\n",
        "model1.load_state_dict(torch.load('/content/model-similarity.pt', map_location=device))\n",
        "model1.eval()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}